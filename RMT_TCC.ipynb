{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando bibliotecas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2cfVKzLtIRg1"
   },
   "outputs": [],
   "source": [
    "#Importando as bibliotecas necessárias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import config\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.io.arff import loadarff\n",
    "\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#Importando as bibliotecas referentes ao XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "#Importando as bibliotecas referentes ao ANN\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RhU0QgcMSZyD"
   },
   "source": [
    "## A fazer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xunbDQxaSAan"
   },
   "source": [
    "## Duvidas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PUh8kiCjVxO0"
   },
   "source": [
    "## Funções"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "byiB0yYdVwHx"
   },
   "outputs": [],
   "source": [
    "#DecisionTree\n",
    "def model_dtree(x_train,y_train,x_test,booster,eta,max_depth,colsample_bytree,subsample,min_child_weight,reg_lambda,num_boost,my_num):\n",
    "    bst = DecisionTreeRegressor().fit(x_train, y_train)\n",
    "    predict = bst.predict(x_test)\n",
    "    return predict\n",
    "\n",
    "#RandomForestRegressor\n",
    "def model_randomForest(x_train,y_train,x_test,my_num):\n",
    "    #booster,eta,max_depth,colsample_bytree,subsample,min_child_weight,reg_lambda,num_boost):\n",
    "    bst = RandomForestRegressor(n_estimators = my_num,n_jobs = -1).fit(x_train,y_train)\n",
    "    predict = bst.predict(x_test)\n",
    "    return predict\n",
    "\n",
    "#SVR\n",
    "def model_svr(x_train,y_train,x_test,ker,gam,c,epsi,shrink,verb,max_it):\n",
    "    bst = SVR(kernel=ker, gamma=gam, C=c, epsilon=epsi, shrinking=shrink, verbose=verb, max_iter=max_it).fit(x_train,y_train)\n",
    "    predict = bst.predict(x_test)\n",
    "    return predict\n",
    "\n",
    "def model_multi_dtree(x_train, y_train, x_test):\n",
    "    model = DecisionTreeRegressor()\n",
    "    bst = MultiOutputRegressor(model).fit(x_train, y_train)\n",
    "    predict = bst.predict(x_test)\n",
    "    return predict\n",
    "\n",
    "def model_ann_global(x_train, y_train, x_test):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape = (x_train.shape[1])))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(y_train.shape[1], activation='linear'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train, epochs=10, batch_size=32, verbose=0, validation_split=0.2)\n",
    "    \n",
    "    predict = model.predict(x_test)\n",
    "    return predict\n",
    "\n",
    "def model_ann_local(x_train, y_train, x_test):\n",
    "    predict_list = []\n",
    "    for i in range(y_train.shape[1]):\n",
    "        model = Sequential()\n",
    "        model.add(Input(shape = x_train.shape[1]))\n",
    "        model.add(Dense(x_train.shape[1]//2, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(x_train.shape[1]//6, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(x_train.shape[1]//18, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(1, activation='linear'))\n",
    "\n",
    "        model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "        model.fit(x_train, y_train[:,i], epochs=10, batch_size=32, verbose=0, validation_split=0.2)\n",
    "\n",
    "        predict = model.predict(x_test)\n",
    "        predict_list.append(predict)\n",
    "    \n",
    "    predictions = np.concatenate(predict_list, axis=1)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def model_xgboost(x_train, y_train, x_test):\n",
    "    param = {'max_depth': 4,\n",
    "             'eta': 0.05, \n",
    "             'objective': 'reg:squarederror',\n",
    "             'booster': 'gbtree',\n",
    "            }\n",
    "    bst = xgb.XGBRegressor(**param, n_estimators=100)\n",
    "    bst.fit(x_train, y_train) \n",
    "    predict = bst.predict(x_test)\n",
    "    return predict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cálculo de erro "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computer_RRMSE_list(real_test,result_p,real_train_mean):\n",
    "    \"\"\"RRMSE: Relative Root Mean Square Error\n",
    "        input: real_test: real test data\n",
    "              result_p: predicted data\n",
    "              real_train_mean: mean of real train data\n",
    "        output: RRMSE list \"\"\"\n",
    "\n",
    "    _list = []\n",
    "    for i in range(result_p.shape[1]):\n",
    "        fenzi = 0\n",
    "        fenmu = 0\n",
    "        for j in range(result_p.shape[0]):\n",
    "            fenzi += (result_p[j,i] - real_test[j,i])**2\n",
    "            fenmu += (real_train_mean[i] - real_test[j,i])**2\n",
    "        _list.append(math.sqrt(fenzi/fenmu))    \n",
    "    return _list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unpvRVKQSTwF"
   },
   "source": [
    "## Implementação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ohf0EgDuYRXL",
    "outputId": "04f5473d-f761-4005-d640-dae2cb96522e"
   },
   "outputs": [],
   "source": [
    "path = \"../TCC/mtr-datasets/\"\n",
    "\n",
    "#text_file = input(\"dataset: \")\n",
    "text_file = 'andro'\n",
    "data, meta = loadarff(path + text_file + \".arff\")\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "data.reset_index(inplace=True)\n",
    "data.replace('?', np.nan, inplace=True)\n",
    "data.replace('     ?', np.nan, inplace=True)\n",
    "data = data.applymap(float)\n",
    "\n",
    "#Normalização\n",
    "scaler = StandardScaler()\n",
    "data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n",
    "\n",
    "\n",
    "if config.all_config[text_file].get('sample_random') == True:\n",
    "    data = data.sample(frac=1,random_state = config.all_config[text_file].get('sample_random_num')).reset_index(drop=True)\n",
    "data = data.fillna(pd.Series(np.nanmean(data,axis=0),index=data.columns))\n",
    "label = data.iloc[:,-config.all_config[text_file].get('targets_num'):].values\n",
    "data = data.iloc[:,:-config.all_config[text_file].get('targets_num')].values\n",
    "\n",
    "error_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MultiOutput Dtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste Multi-dtree\n",
    "loss_list = [] \n",
    "kf = KFold(n_splits=config.all_config[text_file].get('paper_kFold'), shuffle=config.all_config[text_file].get('kfold_random'))\n",
    "for train_index , test_index in kf.split(data):\n",
    "    x_train, x_test = data[train_index], data[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    \n",
    "    result_p_train = model_multi_dtree(x_train, y_train, x_test)\n",
    "    loss_list_RRMSE = computer_RRMSE_list(y_test,result_p_train,np.mean(y_train,axis=0))\n",
    "\n",
    "error_results.append(('MultiOutput Decision Tree', loss_list_RRMSE))\n",
    "# print(\"RRMSE: \", loss_list_RRMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Global "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list_RRMSE = []\n",
    "\n",
    "kf = KFold(n_splits=config.all_config[text_file].get('paper_kFold'),\n",
    "            shuffle=config.all_config[text_file].get('kfold_random'),\n",
    "            random_state=config.all_config[text_file].get('kfold_random_num'))\n",
    "\n",
    "for train_index, test_index in kf.split(data):\n",
    "    x_train, x_test = data[train_index], data[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "\n",
    "    result_p_train = model_randomForest(x_train, y_train, x_test, my_num=100) #call model_randomForest once\n",
    "    \n",
    "    real_train_mean = y_train.mean(axis=0)    \n",
    "    loss_list_RRMSE.append(computer_RRMSE_list(y_test, result_p_train, real_train_mean))\n",
    "\n",
    "loss_list_RRMSE_np = np.array(loss_list_RRMSE)\n",
    "error_results.append(('Random Forest Global', loss_list_RRMSE_np.mean(axis=0)))\n",
    "# print('RRMSE: ', loss_list_RRMSE_np)\n",
    "# print('RRMSE mean: ', loss_list_RRMSE_np.mean(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Local "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list_RRMSE = []\n",
    "\n",
    "kf = KFold(n_splits=config.all_config[text_file].get('paper_kFold'),\n",
    "            shuffle=config.all_config[text_file].get('kfold_random'),\n",
    "            random_state=config.all_config[text_file].get('kfold_random_num'))\n",
    "\n",
    "for train_index, test_index in kf.split(data):\n",
    "    x_train, x_test = data[train_index], data[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "\n",
    "    result_p_train = []\n",
    "    \n",
    "    for i in range(label.shape[1]):\n",
    "\n",
    "        predicted_test = None \n",
    "\n",
    "        if text_file in ['sf1', 'sf2']:\n",
    "            predicted_test = model_svr(x_train, y_train[:,i], x_test,\n",
    "                                    config.all_config[text_file].get('svr1_kernel'),\n",
    "                                    config.all_config[text_file].get('svr1_gamma'),\n",
    "                                    config.all_config[text_file].get('svr1_C'),\n",
    "                                    config.all_config[text_file].get('svr1_epsilon'),\n",
    "                                    config.all_config[text_file].get('svr1_shrinking'),\n",
    "                                    config.all_config[text_file].get('svr1_verbose'),\n",
    "                                    config.all_config[text_file].get('svr1_max_iter'))\n",
    "        else:\n",
    "            predicted_test = model_randomForest(x_train, y_train[:,i], x_test, my_num=100)\n",
    "            \n",
    "        result_p_train.append(predicted_test)\n",
    "\n",
    "    result_p_train = pd.DataFrame(result_p_train).T.values\n",
    "    real_train_mean = y_train.mean(axis=0)    \n",
    "    loss_list_RRMSE.append(computer_RRMSE_list(y_test,result_p_train,real_train_mean))\n",
    "\n",
    "\n",
    "loss_list_RRMSE_np = np.array(loss_list_RRMSE)\n",
    "error_results.append(('Random Forest Local', loss_list_RRMSE_np.mean(axis=0)))\n",
    "# print('RRMSE: ', loss_list_RRMSE_np)\n",
    "# print('RRMSE mean: ',loss_list_RRMSE_np.mean(axis=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANN Global "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 19:17:43.857152: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x290bf0160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x290bf2170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n"
     ]
    }
   ],
   "source": [
    "loss_list_RRMSE = []\n",
    "\n",
    "kf = KFold(n_splits=config.all_config[text_file].get('paper_kFold'),\n",
    "            shuffle=config.all_config[text_file].get('kfold_random'),\n",
    "            random_state=config.all_config[text_file].get('kfold_random_num'))\n",
    "\n",
    "for train_index, test_index in kf.split(data):\n",
    "    x_train, x_test = data[train_index], data[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "\n",
    "    result_p_train = model_ann_global(x_train, y_train, x_test)  # Call model_ann_global once\n",
    "    \n",
    "    real_train_mean = y_train.mean(axis=0)    \n",
    "    loss_list_RRMSE.append(computer_RRMSE_list(y_test, result_p_train, real_train_mean))\n",
    "\n",
    "loss_list_RRMSE_np = np.array(loss_list_RRMSE)\n",
    "error_results.append(('ANN Global', loss_list_RRMSE_np.mean(axis=0)))\n",
    "# print('RRMSE: ', loss_list_RRMSE_np)\n",
    "# print('RRMSE mean: ', loss_list_RRMSE_np.mean(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANN Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n"
     ]
    }
   ],
   "source": [
    "loss_list_RRMSE = []\n",
    "\n",
    "kf = KFold(n_splits=config.all_config[text_file].get('paper_kFold'),\n",
    "            shuffle=config.all_config[text_file].get('kfold_random'),\n",
    "            random_state=config.all_config[text_file].get('kfold_random_num'))\n",
    "\n",
    "for train_index, test_index in kf.split(data):\n",
    "    x_train, x_test = data[train_index], data[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "\n",
    "    result_p_train = model_ann_local(x_train, y_train, x_test)\n",
    "   \n",
    "    real_train_mean = y_train.mean(axis=0)    \n",
    "\n",
    "    result_p_train = pd.DataFrame(result_p_train).values\n",
    "    loss_list_RRMSE.append(computer_RRMSE_list(y_test, result_p_train, real_train_mean))\n",
    "\n",
    "    \n",
    "loss_list_RRMSE_np = np.array(loss_list_RRMSE)\n",
    "error_results.append(('ANN Local', loss_list_RRMSE_np.mean(axis=0)))\n",
    "# print('RRMSE: ', loss_list_RRMSE_np)\n",
    "# print('RRMSE mean: ',loss_list_RRMSE_np.mean(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list_RRMSE = []\n",
    "\n",
    "kf = KFold(n_splits=config.all_config[text_file].get('paper_kFold'),\n",
    "            shuffle=config.all_config[text_file].get('kfold_random'),\n",
    "            random_state=config.all_config[text_file].get('kfold_random_num'))\n",
    "\n",
    "for train_index, test_index in kf.split(data):\n",
    "    x_train, x_test = data[train_index], data[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "\n",
    "    result_p_train = model_xgboost(x_train, y_train, x_test)\n",
    "    \n",
    "    real_train_mean = y_train.mean(axis=0)    \n",
    "    loss_list_RRMSE.append(computer_RRMSE_list(y_test, result_p_train, real_train_mean))\n",
    "\n",
    "loss_list_RRMSE_np = np.array(loss_list_RRMSE)\n",
    "error_results.append(('XGBoost Local', loss_list_RRMSE_np.mean(axis=0)))\n",
    "# print('RRMSE: ', loss_list_RRMSE_np)\n",
    "# print('RRMSE mean: ', loss_list_RRMSE_np.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiOutput Decision Tree RRMSE: [0.40023333002332506, 0.02044705362869795, 0.7193043548966468, 0.7086654929709483, 0.6964982862873742, 0.9877161312990153]\n",
      "Random Forest Global RRMSE: [0.31629909 0.2966071  0.30712246 0.30812334 0.52160143 0.55041904]\n",
      "Random Forest Local RRMSE: [0.39453565 0.27027068 0.33402029 0.34314087 0.6460256  0.59859992]\n",
      "ANN Global RRMSE: [0.87905475 0.86252126 0.96865246 0.99411114 1.03802282 1.00851647]\n",
      "ANN Local RRMSE: [1.05904199 0.98890408 0.98386921 1.01469382 0.97670647 0.94233438]\n",
      "XGBoost Local RRMSE: [0.3899991  0.13958916 0.36069351 0.33912269 0.6791775  0.6680659 ]\n"
     ]
    }
   ],
   "source": [
    "# print the name and value of each model's error result\n",
    "for model, error in error_results:\n",
    "    print(f'{model} RRMSE: {error}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parte errada ainda "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ta errado ainda, \n",
    "# # A funcao model_ann_local ta iterando sobre as colunas\n",
    "# # e nesse código ta iterando de novo sobre as colunas\n",
    "\n",
    "# loss_list_RRMSE = []\n",
    "\n",
    "# kf = KFold(n_splits=config.all_config[text_file].get('paper_kFold'),\n",
    "#             shuffle=config.all_config[text_file].get('kfold_random'),\n",
    "#             random_state=config.all_config[text_file].get('kfold_random_num'))\n",
    "\n",
    "# for train_index, test_index in kf.split(data):\n",
    "#     x_train, x_test = data[train_index], data[test_index]\n",
    "#     y_train, y_test = label[train_index], label[test_index]\n",
    "\n",
    "#     result_p_test = []\n",
    "\n",
    "#     for i in range(label.shape[1]):\n",
    "        \n",
    "#         predicted_test = None \n",
    "\n",
    "#         if text_file in ['sf1', 'sf2']:\n",
    "#             predicted_test = model_svr(x_train, y_train[:,i], x_test, y_test[:,i],\n",
    "#                                     config.all_config[text_file].get('svr1_kernel'),\n",
    "#                                     config.all_config[text_file].get('svr1_gamma'),\n",
    "#                                     config.all_config[text_file].get('svr1_C'),\n",
    "#                                     config.all_config[text_file].get('svr1_epsilon'),\n",
    "#                                     config.all_config[text_file].get('svr1_shrinking'),\n",
    "#                                     config.all_config[text_file].get('svr1_verbose'),\n",
    "#                                     config.all_config[text_file].get('svr1_max_iter'))\n",
    "#         else:\n",
    "#             predicted_test = model_ann_local(x_train, y_train, x_test)\n",
    "        \n",
    "#         result_p_test.append(predicted_test)\n",
    "\n",
    "#     result_p_test = pd.DataFrame(result_p_test).T.values\n",
    "#     real_train_mean = y_train.mean(axis=0)    \n",
    "#     loss_list_RRMSE.append(computer_RRMSE_list(y_test,result_p_test,real_train_mean))\n",
    "\n",
    "\n",
    "# loss_list_RRMSE_np = np.array(loss_list_RRMSE)         \n",
    "# print('RRMSE: ',np.mean(loss_list_RRMSE_np))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
