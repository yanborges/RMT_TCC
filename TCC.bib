%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Yan Gimenez borges at 2023-12-14 18:37:47 -0300 


%% Saved with string encoding Unicode (UTF-8) 



@inproceedings{target_relatedness,
	abstract = {The approach of learning of multiple ``related'' tasks simultaneously has proven quite successful in practice; however, theoretical justification for this success has remained elusive. The starting point for previous work on multiple task learning has been that the tasks to be learned jointly are somehow ``algorithmically related'', in the sense that the results of applying a specific learning algorithm to these tasks are assumed to be similar. We offer an alternative approach, defining relatedness of tasks on the basis of similarity between the example generating distributions that underline these task.},
	address = {Berlin, Heidelberg},
	author = {Ben-David, Shai and Schuller, Reba},
	booktitle = {Learning Theory and Kernel Machines},
	date-added = {2023-12-14 17:27:13 -0300},
	date-modified = {2023-12-14 17:27:13 -0300},
	editor = {Sch{\"o}lkopf, Bernhard and Warmuth, Manfred K.},
	isbn = {978-3-540-45167-9},
	pages = {567--580},
	publisher = {Springer Berlin Heidelberg},
	title = {Exploiting Task Relatedness for Multiple Task Learning},
	year = {2003}}

@inproceedings{global_method_better,
	abstract = {Multi-target regression is concerned with the simultaneous prediction of multiple continuous target variables based on the same set of input variables. It arises in several interesting industrial and environmental application domains, such as ecological modelling and energy forecasting. This paper presents an ensemble method for multi-target regression that constructs new target variables via random linear combinations of existing targets. We discuss the connection of our approach with multi-label classification algorithms, in particular RAkEL, which originally inspired this work, and a family of recent multi-label classification algorithms that involve output coding. Experimental results on 12 multi-target datasets show that it performs significantly better than a strong baseline that learns a single model for each target using gradient boosting and compares favourably to multi-objective random forest approach, which is a state-of-the-art approach. The experiments further show that our approach improves more when stronger unconditional dependencies exist among the targets.},
	address = {Berlin, Heidelberg},
	author = {Tsoumakas, Grigorios and Spyromitros-Xioufis, Eleftherios and Vrekou, Aikaterini and Vlahavas, Ioannis},
	booktitle = {Machine Learning and Knowledge Discovery in Databases},
	date-added = {2023-12-14 17:22:50 -0300},
	date-modified = {2023-12-14 17:22:50 -0300},
	editor = {Calders, Toon and Esposito, Floriana and H{\"u}llermeier, Eyke and Meo, Rosa},
	isbn = {978-3-662-44845-8},
	pages = {225--240},
	publisher = {Springer Berlin Heidelberg},
	title = {Multi-target Regression via Random Linear Target Combinations},
	year = {2014}}

@inproceedings{t_modelos,
	abstract = {In this work, we address the task of learning ensembles of predictive models for predicting multiple continuous variables, i.e., multi-target regression (MTR). In contrast to standard regression, where the output is a single scalar value, in MTR the output is a data structure -- a tuple/vector of continuous variables. The task of MTR is recently gaining increasing interest by the research community due to its applicability in a practically relevant domains. More specifically, we consider the Extra-Tree ensembles -- the overall top performer in the DREAM4 and DREAM5 challenges for gene network reconstruction. We extend this method for the task of multi-target regression and call the extension Extra-PCTs ensembles. As base predictive models, we propose to use predictive clustering trees (PCTs) -- a generalization of decision trees for predicting structured outputs, including multiple continuous variables. We consider both global and local prediction of the multiple variables, the former based on a single model that predicts all of the target variables simultaneously and the latter based on a collection of models, each predicting a single target variable. We conduct an experimental evaluation of the proposed method on a collection of 10 benchmark datasets for with multiple continuous targets and compare its performance to random forests of PCTs. The results reveal that a multi-target Extra-PCTs ensemble performs statistically significantly better than a single multi-target or single-target PCT. Next, the performance among the different ensemble learning methods is not statistically significantly different, while multi-target Extra-PCTs ensembles are the best performing method. Finally, in terms of efficiency (running times and model complexity), both multi-target variants of the ensemble methods are more efficient and produce smaller models as compared to the single-target ensembles.},
	address = {Cham},
	author = {Kocev, Dragi and Ceci, Michelangelo},
	booktitle = {Discovery Science},
	date-added = {2023-12-14 17:21:07 -0300},
	date-modified = {2023-12-14 17:21:07 -0300},
	editor = {Japkowicz, Nathalie and Matwin, Stan},
	isbn = {978-3-319-24282-8},
	pages = {86--100},
	publisher = {Springer International Publishing},
	title = {Ensembles of Extremely Randomized Trees for Multi-target Regression},
	year = {2015}}

@article{algoritmos_globais,
	abstract = {In recent years, a plethora of approaches have been proposed to deal with the increasingly challenging task of multi-output regression. This study provides a survey on state-of-the-art multi-output regression methods, that are categorized as problem transformation and algorithm adaptation methods. In addition, we present the mostly used performance evaluation measures, publicly available data sets for multi-output regression real-world problems, as well as open-source software frameworks. WIREs Data Mining Knowl Discov 2015, 5:216--233. doi: 10.1002/widm.1157 This article is categorized under: Technologies > Machine Learning},
	author = {Borchani, Hanen and Varando, Gherardo and Bielza, Concha and Larra{\~n}aga, Pedro},
	date-added = {2023-12-14 17:19:29 -0300},
	date-modified = {2023-12-14 17:19:29 -0300},
	doi = {https://doi.org/10.1002/widm.1157},
	eprint = {https://wires.onlinelibrary.wiley.com/doi/pdf/10.1002/widm.1157},
	journal = {WIREs Data Mining and Knowledge Discovery},
	number = {5},
	pages = {216-233},
	title = {A survey on multi-output regression},
	url = {https://wires.onlinelibrary.wiley.com/doi/abs/10.1002/widm.1157},
	volume = {5},
	year = {2015},
	bdsk-url-1 = {https://wires.onlinelibrary.wiley.com/doi/abs/10.1002/widm.1157},
	bdsk-url-2 = {https://doi.org/10.1002/widm.1157}}

@article{Ensemble_tree,
	abstract = {In this paper, we address the task of learning models for predicting structured outputs. We consider both global and local predictions of structured outputs, the former based on a single model that predicts the entire output structure and the latter based on a collection of models, each predicting a component of the output structure. We use ensemble methods and apply them in the context of predicting structured outputs. We propose to build ensemble models consisting of predictive clustering trees, which generalize classification trees: these have been used for predicting different types of structured outputs, both locally and globally. More specifically, we develop methods for learning two types of ensembles (bagging and random forests) of predictive clustering trees for global and local predictions of different types of structured outputs. The types of outputs considered correspond to different predictive modeling tasks: multi-target regression, multi-target classification, and hierarchical multi-label classification. Each of the combinations can be applied both in the context of global prediction (producing a single ensemble) or local prediction (producing a collection of ensembles). We conduct an extensive experimental evaluation across a range of benchmark datasets for each of the three types of structured outputs. We compare ensembles for global and local prediction, as well as single trees for global prediction and tree collections for local prediction, both in terms of predictive performance and in terms of efficiency (running times and model complexity). The results show that both global and local tree ensembles perform better than the single model counterparts in terms of predictive power. Global and local tree ensembles perform equally well, with global ensembles being more efficient and producing smaller models, as well as needing fewer trees in the ensemble to achieve the maximal performance.},
	author = {Dragi Kocev and Celine Vens and Jan Struyf and Sa{\v s}o D{\v z}eroski},
	date-added = {2023-12-14 17:16:31 -0300},
	date-modified = {2023-12-14 17:16:31 -0300},
	doi = {https://doi.org/10.1016/j.patcog.2012.09.023},
	issn = {0031-3203},
	journal = {Pattern Recognition},
	number = {3},
	pages = {817-833},
	title = {Tree ensembles for predicting structured outputs},
	url = {https://www.sciencedirect.com/science/article/pii/S003132031200430X},
	volume = {46},
	year = {2013},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S003132031200430X},
	bdsk-url-2 = {https://doi.org/10.1016/j.patcog.2012.09.023}}

@article{Boosted_Neural_Network,
	abstract = {In this paper, the concept of ensemble learning is adopted and applied to modeling multi-target regression problems with high-dimensional feature spaces and a small number of instances. A novel neural network ensemble (NNE) model is introduced, called Boosted-NNE based on notions from boosting, subspace projection methods and the negative correlation learning algorithm (NCL). Rather than using an entire feature space for training each component in the Boosted-NNE, a new cluster-based subspace projection method (CLSP) is proposed to automatically construct a low-dimensional input space with focus on the difficult instances in each step of the boosting approach. To enhance diversity in the Boosted-NNE, a new, sequential negative correlation learning algorithm (SNCL) is proposed to train negatively correlated components. Furthermore, the constrained least mean square error (CLMS) algorithm is employed to obtain the optimal weights of components in the combination module. The proposed Boosted-NNE model is compared with other ensemble and single models using four real cases of multi-target regression problems. The experimental results indicate that using the SNCL in combination with the CLSP method offers the capability to improve the diversity and accuracy of the Boosted-NNE. Thus, this model seems a promising alternative for modeling high-dimensional multi-target regression problems.},
	author = {Esmaeil Hadavandi and Jamal Shahrabi and Shahaboddin Shamshirband},
	date-added = {2023-12-14 17:15:28 -0300},
	date-modified = {2023-12-14 17:15:28 -0300},
	doi = {https://doi.org/10.1016/j.engappai.2015.06.022},
	issn = {0952-1976},
	journal = {Engineering Applications of Artificial Intelligence},
	pages = {204-219},
	title = {A novel Boosted-neural network ensemble for modeling multi-target regression problems},
	url = {https://www.sciencedirect.com/science/article/pii/S095219761500144X},
	volume = {45},
	year = {2015},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S095219761500144X},
	bdsk-url-2 = {https://doi.org/10.1016/j.engappai.2015.06.022}}

@article{Random_Forest,
	abstract = {An important consideration in conservation and biodiversity planning is an appreciation of the condition or integrity of ecosystems. In this study, we have applied various machine learning methods to the problem of predicting the condition or quality of the remnant indigenous vegetation across an extensive area of south-eastern Australia---the state of Victoria. The field data were obtained using the `habitat hectares' approach. This rapid assessment technique produces multiple scores that describe the condition of various attributes of the vegetation at a given site. Multiple sites were assessed and subsequently circumscribed with GIS and remote-sensed data. We explore and compare two approaches for modelling this type of data: to learn a model for each score separately (single-target approach, a regression tree), or to learn one model for all scores simultaneously (multi-target approach, a multi-target regression tree). In order to lift the predictive performance, we also employ ensembles (bagging and random forests) of regression trees and multi-target regression trees. Our results demonstrate the advantages of a multi-target over a single-target modelling approach. While there is no statistically significant difference between the multi-target and single-target models in terms of model performance, the multi-target models are smaller and faster to learn than the single-target ones. Ensembles of multi-target models, also, improve the spatial prediction of condition. The usefulness of models of vegetation condition is twofold. First, they provide an enhanced knowledge and understanding of the condition of different indigenous vegetation types, and identify possible biophysical and landscape attributes that may contribute to vegetation decline. Second, these models may be used to map the condition of indigenous vegetation, in support of biodiversity planning, management and investment decisions.},
	author = {Dragi Kocev and Sa{\v s}o D{\v z}eroski and Matt D. White and Graeme R. Newell and Peter Griffioen},
	date-added = {2023-12-14 17:14:41 -0300},
	date-modified = {2023-12-14 17:14:42 -0300},
	doi = {https://doi.org/10.1016/j.ecolmodel.2009.01.037},
	issn = {0304-3800},
	journal = {Ecological Modelling},
	number = {8},
	pages = {1159-1168},
	title = {Using single- and multi-target regression trees and ensembles to model a compound index of vegetation condition},
	url = {https://www.sciencedirect.com/science/article/pii/S0304380009000775},
	volume = {220},
	year = {2009},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0304380009000775},
	bdsk-url-2 = {https://doi.org/10.1016/j.ecolmodel.2009.01.037}}

@article{trend,
	abstract = {Over recent years data mining has been establishing itself as one of the major disciplines in computer science with growing industrial impact. Undoubtedly, research in data mining will continue and even increase over coming decades. In this article, we sketch our vision of the future of data mining. Starting from the classic definition of ``data mining'', we elaborate on topics that ---in our opinion ---will set trends in data mining.},
	author = {Kriegel, Hans-Peter and Borgwardt, Karsten M. and Kr{\"o}ger, Peer and Pryakhin, Alexey and Schubert, Matthias and Zimek, Arthur},
	date = {2007/08/01},
	date-added = {2023-12-11 18:31:15 -0300},
	date-modified = {2023-12-11 18:31:15 -0300},
	doi = {10.1007/s10618-007-0067-9},
	id = {Kriegel2007},
	isbn = {1573-756X},
	journal = {Data Mining and Knowledge Discovery},
	number = {1},
	pages = {87--97},
	title = {Future trends in data mining},
	url = {https://doi.org/10.1007/s10618-007-0067-9},
	volume = {15},
	year = {2007},
	bdsk-url-1 = {https://doi.org/10.1007/s10618-007-0067-9}}

@article{importance,
	author = {Yang, Qiang and Wu, Xindong},
	date-added = {2023-12-11 18:30:08 -0300},
	date-modified = {2023-12-11 18:30:08 -0300},
	doi = {10.1142/S0219622006002258},
	journal = {International Journal of Information Technology & Decision Making (IJITDM)},
	month = {12},
	pages = {597-604},
	title = {10 Challenging Problems in Data Mining Research},
	volume = {05},
	year = {2006},
	bdsk-url-1 = {https://doi.org/10.1142/S0219622006002258}}

@article{MTR_challenges,
	author = {Zhen, Xiantong and Yu, Mengyang and He, Xiaofei and Li, Shuo},
	date-added = {2023-12-11 18:27:39 -0300},
	date-modified = {2023-12-11 18:27:39 -0300},
	doi = {10.1109/TPAMI.2017.2688363},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	number = {2},
	pages = {497-504},
	title = {Multi-Target Regression via Robust Low-Rank Learning},
	volume = {40},
	year = {2018},
	bdsk-url-1 = {https://doi.org/10.1109/TPAMI.2017.2688363}}

@article{ecologia,
	author = {Aho, Timo and {\v Z}enko, Bernard and D{\v z}zeroski, Sa{\v s}o and Elomaa, Tapio and Brodley, Carla},
	date-added = {2023-12-11 18:13:02 -0300},
	date-modified = {2023-12-11 18:13:02 -0300},
	isbn = {1532-4435},
	journal = {Journal of Machine Learning Research},
	number = {8},
	title = {Multi-target regression with rule ensembles.},
	volume = {13},
	year = {2012}}

@article{PLN,
	abstract = {This paper addresses the problem of multi-domain spoken language understanding (SLU) where domain detection and domain-dependent semantic tagging problems are combined. We present a transfer learning approach to the multi-domain SLU problem in which multiple domain-specific data sources can be incorporated. To implement multi-domain SLU with transfer learning, we introduce a triangular-chain structured model. This model effectively learns multiple domains in parallel, and allows use of domain-independent patterns among domains to create a better model for the target domain. We demonstrate that the proposed method outperforms baseline models on dialog data for multi-domain SLU problems.},
	author = {Minwoo Jeong and Gary Geunbae Lee},
	date-added = {2023-12-11 18:08:03 -0300},
	date-modified = {2023-12-11 18:08:03 -0300},
	doi = {https://doi.org/10.1016/j.specom.2009.01.001},
	issn = {0167-6393},
	journal = {Speech Communication},
	number = {5},
	pages = {412-424},
	title = {Multi-domain spoken language understanding with transfer learning},
	url = {https://www.sciencedirect.com/science/article/pii/S0167639309000028},
	volume = {51},
	year = {2009},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0167639309000028},
	bdsk-url-2 = {https://doi.org/10.1016/j.specom.2009.01.001}}

@article{medical_image,
	abstract = {Direct estimation of cardiac ventricular volumes has become increasingly popular and important in cardiac function analysis due to its effectiveness and efficiency by avoiding an intermediate segmentation step. However, existing methods rely on either intensive user inputs or problematic assumptions. To realize the full capacities of direct estimation, this paper presents a general, fully learning-based framework for direct bi-ventricular volume estimation, which removes user inputs and unreliable assumptions. We formulate bi-ventricular volume estimation as a general regression framework which consists of two main full learning stages: unsupervised cardiac image representation learning by multi-scale deep networks and direct bi-ventricular volume estimation by random forests. By leveraging strengths of generative and discriminant learning, the proposed method produces high correlations of around 0.92 with ground truth by human experts for both the left and right ventricles using a leave-one-subject-out cross validation, and largely outperforms existing direct methods on a larger dataset of 100 subjects including both healthy and diseased cases with twice the number of subjects used in previous methods. More importantly, the proposed method can not only be practically used in clinical cardiac function analysis but also be easily extended to other organ volume estimation tasks.},
	author = {Xiantong Zhen and Zhijie Wang and Ali Islam and Mousumi Bhaduri and Ian Chan and Shuo Li},
	date-added = {2023-12-11 18:06:07 -0300},
	date-modified = {2023-12-11 18:23:00 -0300},
	doi = {https://doi.org/10.1016/j.media.2015.07.003},
	issn = {1361-8415},
	journal = {Medical Image Analysis},
	pages = {120-129},
	title = {Multi-scale deep networks and regression forests for direct bi-ventricular volume estimation},
	url = {https://www.sciencedirect.com/science/article/pii/S1361841515001024},
	volume = {30},
	year = {2016},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S1361841515001024},
	bdsk-url-2 = {https://doi.org/10.1016/j.media.2015.07.003}}

@article{computer_vision,
	author = {Yan, Yan and Ricci, Elisa and Subramanian, Ramanathan and Liu, Gaowen and Lanz, Oswald and Sebe, Nicu},
	date-added = {2023-12-11 18:05:29 -0300},
	date-modified = {2023-12-11 18:05:29 -0300},
	doi = {10.1109/TPAMI.2015.2477843},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	number = {6},
	pages = {1070-1083},
	title = {A Multi-Task Learning Framework for Head Pose Estimation under Target Motion},
	volume = {38},
	year = {2016},
	bdsk-url-1 = {https://doi.org/10.1109/TPAMI.2015.2477843}}

@article{W.Groves,
	abstract = {In many practical applications of supervised learning the task involves the prediction of multiple target variables from a common set of input variables. When the prediction targets are binary the task is called multi-label classification, while when the targets are continuous the task is called multi-target regression. In both tasks, target variables often exhibit statistical dependencies and exploiting them in order to improve predictive accuracy is a core challenge. A family of multi-label classification methods address this challenge by building a separate model for each target on an expanded input space where other targets are treated as additional input variables. Despite the success of these methods in the multi-label classification domain, their applicability and effectiveness in multi-target regression has not been studied until now. In this paper, we introduce two new methods for multi-target regression, called stacked single-target and ensemble of regressor chains, by adapting two popular multi-label classification methods of this family. Furthermore, we highlight an inherent problem of these methods---a discrepancy of the values of the additional input variables between training and prediction---and develop extensions that use out-of-sample estimates of the target variables during training in order to tackle this problem. The results of an extensive experimental evaluation carried out on a large and diverse collection of datasets show that, when the discrepancy is appropriately mitigated, the proposed methods attain consistent improvements over the independent regressions baseline. Moreover, two versions of Ensemble of Regression Chains perform significantly better than four state-of-the-art methods including regularization-based multi-task learning methods and a multi-objective random forest approach.},
	author = {Spyromitros-Xioufis, Eleftherios and Tsoumakas, Grigorios and Groves, William and Vlahavas, Ioannis},
	date = {2016/07/01},
	date-added = {2023-12-11 18:04:16 -0300},
	date-modified = {2023-12-11 18:04:16 -0300},
	doi = {10.1007/s10994-016-5546-z},
	id = {Spyromitros-Xioufis2016},
	isbn = {1573-0565},
	journal = {Machine Learning},
	number = {1},
	pages = {55--98},
	title = {Multi-target regression via input space expansion: treating targets as inputs},
	url = {https://doi.org/10.1007/s10994-016-5546-z},
	volume = {104},
	year = {2016},
	bdsk-url-1 = {https://doi.org/10.1007/s10994-016-5546-z}}

@article{water,
	abstract = {We address the problem of inferring chemical parameters of river water quality from biological ones. This task is important for enabling selective chemical monitoring of river water quality. We apply machine learning, in particular regression tree induction, to biological and chemical data on the water quality of Slovenian rivers. Regression trees are constructed that predict values of chemical parameters from data on the presence of bioindicator taxa at the species and family levels.},
	author = {D{\v z}eroski, Sa{\v s}o and Dem{\v s}ar, Damjan and Grbovi{\'c}, Jasna},
	date = {2000/07/01},
	date-added = {2023-12-11 18:02:34 -0300},
	date-modified = {2023-12-11 18:02:43 -0300},
	doi = {10.1023/A:1008323212047},
	id = {D{\v z}eroski2000},
	isbn = {1573-7497},
	journal = {Applied Intelligence},
	number = {1},
	pages = {7--17},
	title = {Predicting Chemical Parameters of River Water Quality from Bioindicator Data},
	url = {https://doi.org/10.1023/A:1008323212047},
	volume = {13},
	year = {2000},
	bdsk-url-1 = {https://doi.org/10.1023/A:1008323212047}}
